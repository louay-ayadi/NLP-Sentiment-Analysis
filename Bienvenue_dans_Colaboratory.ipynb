{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Bienvenue dans Colaboratory !</h1>\n",
        "\n",
        "\n",
        "Colaboratory est un environnement de notebook Jupyter qui ne nécessite aucune configuration et qui s'exécute entièrement dans le cloud.\n",
        "\n",
        "Il vous permet d'écrire et d'exécuter du code, de sauvegarder et partager vos analyses, et d'accéder à de puissantes ressources informatiques. Tout cela gratuitement, depuis votre navigateur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xitplqMNk_Hc",
        "outputId": "ed4f60d2-878d-4056-c438-352dac39a112",
        "colab": {
          "height": 420
        }
      },
      "source": [
        "#@title Présentation de Colaboratory { display-mode: \"form\" }\n",
        "#@markdown Cette vidéo de trois minutes offre un aperçu des fonctionnalités principales de Colaboratory :\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"400\"\n",
              "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Premiers pas\n",
        "\n",
        "Le document que vous consultez est un <a href=\"https://jupyter.org/\">notebook Jupyter</a>, hébergé dans Colaboratory. Il ne s'agit pas d'une page statique, mais d'un environnement interactif qui vous permet d'écrire et d'exécuter du code en Python ou dans un autre langage.\n",
        "\n",
        "Voici par exemple une <strong>cellule de code</strong> avec un bref script en Python qui calcule une valeur, l'enregistre dans une variable et imprime le résultat :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "outputId": "5626194c-e802-4293-942d-2908885c3c1f",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "Pour exécuter le code dans la cellule ci-dessus, sélectionnez-le en cliquant dessus, puis cliquez sur le bouton de lecture à gauche du code, ou utilisez le raccourci clavier Commande/Ctrl+Entrée.\n",
        "\n",
        "Toutes les cellules modifient le même état général. Les variables que vous définissez en exécutant une cellule peuvent donc être utilisées dans d'autres cellules :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "Pour en savoir plus sur les notebooks Colaboratory et leur utilisation, consultez <a href=\"/notebooks/basic_features_overview.ipynb\">Présentation de Colaboratory</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## Autres ressources\n",
        "\n",
        "Découvrez comment optimiser votre utilisation de Python, Jupyter, Colaboratory et d'autres outils associés à l'aide des ressources suivantes :\n",
        "\n",
        "### Travailler avec les notebooks dans Colaboratory\n",
        "- [Présentation de Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide de Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importer des bibliothèques et installer des dépendances](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Enregistrer et charger des notebooks dans GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Formes interactives](/notebooks/forms.ipynb)\n",
        "- [Widgets interactifs](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 dans Colab](/notebooks/tensorflow_version.ipynb)\n",
        "\n",
        "### Utiliser les données\n",
        "- [Chargement de données : Drive, Sheets, et Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Graphiques : visualiser les données](/notebooks/charts.ipynb)\n",
        "- [Premiers pas avec BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Cours d'initiation au Machine Learning\n",
        "Il s'agit de quelques-uns des notebooks de la formation Google en ligne sur le machine learning. Consultez la <a href=\"https://developers.google.com/machine-learning/crash-course/\">formation complète en ligne</a> pour en savoir plus.\n",
        "- [Introduction à pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Concepts de TensorFlow](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [Premiers pas avec TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Introduction aux réseaux de neurones](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Introduction aux données creuses et aux représentations vectorielles continues](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "### Utiliser le matériel accéléré\n",
        "- [TensorFlow avec des GPU](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow avec des TPU](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "## Exemples de machine learning : projet Seedbank\n",
        "\n",
        "Pour voir des exemples de bout en bout des analyses interactives de machine learning rendues possibles par Colaboratory, découvrez le projet <a href=\"https://research.google.com/seedbank/\">Seedbank</a>.\n",
        "\n",
        "Voici quelques exemples :\n",
        "\n",
        "- <a href=\"https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras\">Transfert de style neuronal</a> : utiliser le deep learning pour transférer un style d'une image à une autre.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/ez_nsynth\">EZ NSynth</a> : synthétiser des sons avec les auto-encodeurs WaveNet.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus\">Fashion MNIST avec Keras et TPU</a> : classer des images liées à la mode en utilisant le deep learning.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/deepdream\">DeepDream</a> : produire des images DeepDream à partir de vos propres photos.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/convolutional_vae\">Auto-encodeur variationnel convolutif</a> : créer un modèle génératif de chiffres manuscrits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYM7Wqlr7Q82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "c272bd50-c380-4fdf-b5ad-467d46e99a9e"
      },
      "source": [
        "#download the data\n",
        "from keras.datasets import imdb \n",
        "top_words = 5000 \n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1bS80mX7RXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy \n",
        "from keras.datasets import imdb \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import LSTM \n",
        "from keras.layers.embeddings import Embedding \n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz6BNLgf7Ue-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility \n",
        "numpy.random.seed(7) \n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest \n",
        "top_words = 5000 \n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aK8Hfo_7kOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0070130d-3d91-4a77-c492-46e0164bb484"
      },
      "source": [
        "import keras\n",
        "NUM_WORDS=1000 # only use top 1000 words\n",
        "INDEX_FROM=3   # word index offset\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in X_train[0] ))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly <UNK> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <UNK> with us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45zPKB8z7nv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a73d7b7f-00b2-4f8d-ad2b-4a1bf4b638d0"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "docs = ['Gut gemacht',\n",
        "\t\t'Gute arbeit',\n",
        "\t\t'Super idee',\n",
        "\t\t'Perfekt erledigt',\n",
        "\t\t'exzellent',\n",
        "\t\t'naja',\n",
        "\t\t'Schwache arbeit.',\n",
        "\t\t'Nicht gut',\n",
        "\t\t'Miese arbeit.',\n",
        "\t\t'Hätte es besser machen können.']\n",
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7, 18], [21, 18], [28, 24], [49, 1], [39], [31], [46, 18], [47, 7], [29, 18], [19, 10, 12, 17, 25]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72TmEAsX7qjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# truncate and pad the review sequences \n",
        "max_review_length = 500 \n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length) \n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePvgClpK7tqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "408872aa-8f16-436c-d5c1-8d8a7ee0b8ab"
      },
      "source": [
        "pd.DataFrame(X_train).head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>460</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "      <th>463</th>\n",
              "      <th>464</th>\n",
              "      <th>465</th>\n",
              "      <th>466</th>\n",
              "      <th>467</th>\n",
              "      <th>468</th>\n",
              "      <th>469</th>\n",
              "      <th>470</th>\n",
              "      <th>471</th>\n",
              "      <th>472</th>\n",
              "      <th>473</th>\n",
              "      <th>474</th>\n",
              "      <th>475</th>\n",
              "      <th>476</th>\n",
              "      <th>477</th>\n",
              "      <th>478</th>\n",
              "      <th>479</th>\n",
              "      <th>480</th>\n",
              "      <th>481</th>\n",
              "      <th>482</th>\n",
              "      <th>483</th>\n",
              "      <th>484</th>\n",
              "      <th>485</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>134</td>\n",
              "      <td>476</td>\n",
              "      <td>26</td>\n",
              "      <td>480</td>\n",
              "      <td>5</td>\n",
              "      <td>144</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>51</td>\n",
              "      <td>36</td>\n",
              "      <td>28</td>\n",
              "      <td>224</td>\n",
              "      <td>92</td>\n",
              "      <td>25</td>\n",
              "      <td>104</td>\n",
              "      <td>4</td>\n",
              "      <td>226</td>\n",
              "      <td>65</td>\n",
              "      <td>16</td>\n",
              "      <td>38</td>\n",
              "      <td>1334</td>\n",
              "      <td>88</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>283</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>4472</td>\n",
              "      <td>113</td>\n",
              "      <td>103</td>\n",
              "      <td>32</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>178</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>152</td>\n",
              "      <td>491</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>1212</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>371</td>\n",
              "      <td>78</td>\n",
              "      <td>22</td>\n",
              "      <td>625</td>\n",
              "      <td>64</td>\n",
              "      <td>1382</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>168</td>\n",
              "      <td>145</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>1690</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>1355</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>52</td>\n",
              "      <td>154</td>\n",
              "      <td>462</td>\n",
              "      <td>33</td>\n",
              "      <td>89</td>\n",
              "      <td>78</td>\n",
              "      <td>285</td>\n",
              "      <td>16</td>\n",
              "      <td>145</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>272</td>\n",
              "      <td>40</td>\n",
              "      <td>57</td>\n",
              "      <td>31</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>47</td>\n",
              "      <td>6</td>\n",
              "      <td>2307</td>\n",
              "      <td>51</td>\n",
              "      <td>9</td>\n",
              "      <td>170</td>\n",
              "      <td>23</td>\n",
              "      <td>595</td>\n",
              "      <td>116</td>\n",
              "      <td>595</td>\n",
              "      <td>1352</td>\n",
              "      <td>13</td>\n",
              "      <td>191</td>\n",
              "      <td>79</td>\n",
              "      <td>638</td>\n",
              "      <td>89</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>106</td>\n",
              "      <td>607</td>\n",
              "      <td>624</td>\n",
              "      <td>35</td>\n",
              "      <td>534</td>\n",
              "      <td>6</td>\n",
              "      <td>227</td>\n",
              "      <td>7</td>\n",
              "      <td>129</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>687</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3693</td>\n",
              "      <td>42</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>121</td>\n",
              "      <td>59</td>\n",
              "      <td>456</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>265</td>\n",
              "      <td>12</td>\n",
              "      <td>575</td>\n",
              "      <td>111</td>\n",
              "      <td>153</td>\n",
              "      <td>159</td>\n",
              "      <td>59</td>\n",
              "      <td>16</td>\n",
              "      <td>1447</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>586</td>\n",
              "      <td>482</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "      <td>96</td>\n",
              "      <td>59</td>\n",
              "      <td>716</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>172</td>\n",
              "      <td>65</td>\n",
              "      <td>9</td>\n",
              "      <td>579</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>242</td>\n",
              "      <td>955</td>\n",
              "      <td>48</td>\n",
              "      <td>25</td>\n",
              "      <td>279</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>1685</td>\n",
              "      <td>195</td>\n",
              "      <td>25</td>\n",
              "      <td>238</td>\n",
              "      <td>60</td>\n",
              "      <td>796</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>671</td>\n",
              "      <td>7</td>\n",
              "      <td>2804</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>559</td>\n",
              "      <td>154</td>\n",
              "      <td>888</td>\n",
              "      <td>7</td>\n",
              "      <td>726</td>\n",
              "      <td>50</td>\n",
              "      <td>26</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>566</td>\n",
              "      <td>30</td>\n",
              "      <td>579</td>\n",
              "      <td>21</td>\n",
              "      <td>64</td>\n",
              "      <td>2574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>233</td>\n",
              "      <td>334</td>\n",
              "      <td>207</td>\n",
              "      <td>126</td>\n",
              "      <td>224</td>\n",
              "      <td>12</td>\n",
              "      <td>562</td>\n",
              "      <td>298</td>\n",
              "      <td>2167</td>\n",
              "      <td>1272</td>\n",
              "      <td>7</td>\n",
              "      <td>2601</td>\n",
              "      <td>5</td>\n",
              "      <td>516</td>\n",
              "      <td>988</td>\n",
              "      <td>43</td>\n",
              "      <td>8</td>\n",
              "      <td>79</td>\n",
              "      <td>120</td>\n",
              "      <td>15</td>\n",
              "      <td>595</td>\n",
              "      <td>13</td>\n",
              "      <td>784</td>\n",
              "      <td>25</td>\n",
              "      <td>3171</td>\n",
              "      <td>18</td>\n",
              "      <td>165</td>\n",
              "      <td>170</td>\n",
              "      <td>143</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>226</td>\n",
              "      <td>251</td>\n",
              "      <td>7</td>\n",
              "      <td>61</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5     6    ...  493  494  495  496  497  498   499\n",
              "0    0    0    0    0    0    0     0  ...   32   15   16    2   19  178    32\n",
              "1    0    0    0    0    0    0     0  ...   33   89   78  285   16  145    95\n",
              "2    0    0    0    0    0    0     0  ...   35  534    6  227    7  129   113\n",
              "3  687   23    4    2    2    6  3693  ...   15  566   30  579   21   64  2574\n",
              "4    0    0    0    0    0    0     0  ...    2    6  226  251    7   61   113\n",
              "\n",
              "[5 rows x 500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcjCYsc77wU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "4c196239-7be7-4e84-b730-a4f67786f093"
      },
      "source": [
        "# create the model \n",
        "embedding_vector_length = 32 \n",
        "model = Sequential() \n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length)) \n",
        "model.add(LSTM(100)) \n",
        "#model.add(Flatten()) \n",
        "model.add(Dense(1, activation='sigmoid')) \n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
        "print(model.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_AV6ft74T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "5e35415f-108a-4454-ed22-f0cf61ccdf4e"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "25000/25000 [==============================] - 556s 22ms/step - loss: 0.4472 - acc: 0.7835 - val_loss: 0.3563 - val_acc: 0.8516\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 540s 22ms/step - loss: 0.3153 - acc: 0.8742 - val_loss: 0.3225 - val_acc: 0.8701\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 522s 21ms/step - loss: 0.2585 - acc: 0.8984 - val_loss: 0.3228 - val_acc: 0.8689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3cd9b3780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLYRKPUO_k7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9e66679-400e-4cfb-cad8-27521423eb8e"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPw3r52M78Zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Final evaluation of the model \n",
        "scores = model.evaluate(X_test, y_test, verbose=0) \n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}